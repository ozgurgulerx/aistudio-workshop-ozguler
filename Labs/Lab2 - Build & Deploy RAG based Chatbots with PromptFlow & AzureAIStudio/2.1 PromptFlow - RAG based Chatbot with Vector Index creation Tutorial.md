
![Alt text](../../media/promptflow-logo.png) 

# Welcome...

Welcome to Azure ML PromptFlow workshop. \
In this workshop we will create a RAG based chatbot using PromptFlow.

# INTRODUCTION to PromptFlow 
Prompt flow is a suite of development tools designed to streamline the end-to-end development cycle of LLM-based AI applications, from ideation, prototyping, testing, evaluation to production deployment and monitoring. It makes prompt engineering much easier and enables you to build LLM apps with production quality.

With prompt flow, you will be able to:

- Create flows that link LLMs, prompts, Python code and other tools together in a executable workflow.
- Debug and iterate your flows, especially the interaction with LLMs with ease.
- Evaluate your flows, calculate quality and performance metrics with larger datasets.
- Integrate the testing and evaluation into your CI/CD system to ensure quality of your flow.
- Deploy your flows to the serving platform you choose or integrate into your appâ€™s code base easily.
- (Optional but highly recommended) Collaborate with your team by leveraging the cloud version of Prompt flow in Azure AI.

For PromptFlow documentation please refer to [link](https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/get-started-prompt-flow?view=azureml-api-2).

(PromptFlow was GA'ed on Nov 11th, 2023. Therefore you no longer need to enable it from under "preview features" in Azure ML))
Go to [ml.azure.com](https://ml.azure.com).


# 1. Create an AzureML Workspace for PromptFlow under AzureML
We need to create a workspace under AzureML for PromptFlow.
![Alt text](../../media/2.1.create-workspace.png) 

Add workspace-name, resource-group and region details. (An existing resource-group can be reused) \
It will take <1 mins for the workspace to be created. \
![Alt text](../../media/2.1.create-workspace-pf.png)

Once the workspace is created. Choose the workspace and click on PromptFlow on the left vertical menu.
![Alt text](../../media/2.1choose-promptflow.png)

# 2. Create required AOAI Deployments and corresponding PromptFlow connections 

PromptFlow uses "connections" to interact with the larger service infrastructure. \
We need to create seperate connections for LLM's weather these are AzureOpenAI models, OS or other external models, registered vector indexes and vector db's  or custom connections for any other 3rd party API's.

For a RAG chatbot - we will need...
- embedding models to embed document chunks 
- a vector index so that document embeddings can be stored to generate relevant and correct contexts for chat queries 
- LLM's to understand the submitted context and respond to chat questions 

Next we will create model deployments and the required PromptFlow connections to be able to use these models for the RAG pipeline.

## 2.1 Create AOAI service and model deployments in AOAI Studio
Go to portal.azure.com, and choose "Azure AI Services"...
![Alt text](../../media/2.1.aoai-service.png)

Next type the service name, the rg and make the service accessible over the Internet. Wait until the service is successfully deployed.
![Alt text](../../media/2.1aoai-service-02.png)

Before we proceed with deploying the models, let's note down service endpoint and API key. (We will need these to create the PromptFlow connection for the created service.)
![Alt text](../../media/2.1aoai-deploy06.png)



Then go to Azure OpenAI Studio to deploy the required models under the service.
![Alt text](../../media/2.1aoai-deploy02.png)

Once in Azure OpenAI Studio, choose deployments in the left vertical menu and create new deployments.
![Alt text](../../media/2.1aoai-deploy03.png)

First deploy the text-embedding-ada-02 model.
![Alt text](../../media/2.1aoai-deploy04.png)

Next deploy the LLM that will be used to drive the chat.
(Prefer a larger context length variant such as gpt-35-turbo 16k as the derived context might be larger than the default 4k tokens of gpt-35-turbo. 
If the model exists in your deployment region prefer the latest variant such as gpt-35-turbu 1106.)
Refer to "[AzureOpenAI model list and region avaialability](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models)" documentation.
Refer to "[AzureOpenAI model quotas](https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits)" documentation to understand how much TPM you can allocate to deployments.

![Alt text](../../media/2.1aoai-deploy05.png)

Once the models (ada-embedding-02 and gpt-35-turbo-16k) are deployed we can proceed to create a connection under PromptFlow for the "AzureOpenAI service".
When defined, PromptFlow will be able to access the deployments over the AOAI connection. (You don't define connections per each deployed model but only for the service itself.)

## 2.2 Create a connection for the AOAI service in PromptFlow  
Once back in PromptFlow workspace, choose connections and create a new connection.
![Alt text](../../media/2.1aoai-deploy0702.png)

Once the subscription ID is chosen, you will automatically see any AOAI service deployment names being pulled.
Choose the one created in the earlier step.

![Alt text](../../media/2.1aoia-deploy08.png)
This completes the AOAI conn creation step.

**3. Create an Azure AI Search Service**
Go to Azure portal and search "Azure AI Search" service (Former Azure Cognitive Search).
Once you are in Azure AI Search, create a new service
![Alt text](../../media/new-AzureAI-search-service.png)

Choose a resource-group (create a new one if doesn't exist). \
"Basic" or "Free" tier will suffice for the purposes of this lab.
![Alt text](../../media/create-search-service-det.png)