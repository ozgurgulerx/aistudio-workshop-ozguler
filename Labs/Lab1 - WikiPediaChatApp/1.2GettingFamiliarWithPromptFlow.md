# Introduction to PromptFlow 

# 1.2.1 Launch PromptFlow on Azure AI Studio (not on Azure ML)
Launch PromptFlow from the vertical menu on the left.
![Alt text](../../media/lab12-1.png)

Create a sample chat flow.
![Alt text](../../media/lab12-2.png)

PrompFlow UI will pop up.
![Alt text](../../media/lab13.png)

# 1.2.1 Configure a PromptFlow Runtime 
PromptFlow code runs on a container runtime which includes  app configurations and dependencies.
Container runtime runs on a compute service. This is either a standard VM you can launch and manage yourself or the new serverless compute (automatic runtime) option can be used.

![Alt text](../../media/lab13-3.png)

Let's use a VM rather than serverless compute for this lab.
![Alt text](../../media/lab13-4.png)

![Alt text](../../media/lab13-6.png)

Choose a VM type...
![Alt text](../../media/lab13-7.png)

Enable ssh access to the VM...
![Alt text](../../media/lab13-8.png)

It will take 1-2 minutes for the VM to launch.
Enable ssh access to the VM...
![Alt text](../../media/lab13-9.png)

Once the lab is up and running choose the compute instance, click activate  and proceed to the flow screen again...
![Alt text](../../media/lab13-10.png)

Finally, you will be able to see the compute instance you have created in the prior steps active on the flow...
![Alt text](../../media/lab3-11.png)

# 1.2.2 Understand the PromptFlow UI & Types of Flow Components 
![Alt text](../../media/lab3-13.png)

E.g. In the flow sample we are using we have an "LLM" flow step.
![Alt text](../../media/lab3-12.png)

PromptFlow UI is organised as individual code modules, each visible in the UI as blocks.
Each block can be of four main types.
1. LLM Step - points to an Azure OpenAI model deployment. \
Let's you define Advanced Features e.g. model hyperparameters, Function Calling and a prompt...
2. Prompt Step -  lets you write a prompt. With the Prompt step you can have the LLM create LLM Variants. \
Each LLM variant is passed through the flow and outputs a different "generation". \
This enables fast prompt engineering.
3. Python Step - PromptFlow lets you write custom code to enable any feature or capability possible by writing a code.
Python Step also enables you to be able to use frameworks like Langchain or LLamaIndex.
4. More Tools Step - More Tools menu includes the following. \
![Alt text](../../media/lab3-14.png)
- Open Model LLM - lets you add non-OpenAI MaaS models e.g. models from Mistral, Meta (Llama-2/3) etc. 
- AzureOpenAI GPT4-Turbo with Vision (preview)
- OpenAI GPT4-V
- Embedding Step 
- Index Lookup - Vector Search Step 
- Content Safety model - to filter out prompts and/or generations for hazardous or offensive content. (More on this later)

# 1.2.2 Run the sample Chat Flow 
We will now run the sample Chat Flow by populating the LLM configuration (endpoint / deployed model details)...

![Alt text](../../media/lab3-122-1.png)

Save the Flow and click on Chat to go to the Chat UI...
![Alt text](../../media/lab3-122-2.png)