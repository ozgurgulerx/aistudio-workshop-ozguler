# Azure AI Content Safety 

The [Azure AI Content Safety service](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/overview) is designed to help developers ensure that the content generated by their applications remains safe and appropriate. This service is particularly useful for applications that incorporate user-generated content or rely on AI models to generate content dynamically.

Here's a breakdown of what it typically offers:

Content Moderation: The service can automatically detect potentially offensive or risky content across text, images, and videos. It includes checks for profanity, adult content, hate speech, and other types of content that might not be suitable for all audiences.
Custom Rules and Filters: Developers can define custom moderation rules tailored to the specific needs and context of their application. This allows for greater control over what is considered acceptable in different scenarios.
Machine Learning Models: Leveraging Azure's machine learning capabilities, the service can be trained to recognize complex patterns and nuances in content that simpler rule-based systems might miss.
Integration and Scalability: As part of the Azure ecosystem, this service integrates well with other Azure services, allowing for scalable solutions that can handle large volumes of content.
Real-Time Processing: It provides real-time content analysis capabilities, making it suitable for applications that need immediate moderation decisions, such as live streaming platforms or instant messaging apps.
This service is a part of Azure's broader set of cognitive services, aimed at empowering developers to build AI-driven applications with built-in safeguards for content safety.

## Creating an Azure AI Content Safety Service through Azure Portal 
Find the service in the portal...
![Alt text](../../media/1231.png)

Choose "Create"...
![Alt text](../../media/1232.png)

Add service details, try to use the same resource-group as your AI Studio Hub resource to consolidate AI costs. Free tier will be fine for the purposes of this workshop.
![Alt text](../../media/1233.png)


[Optional] You can now go to Content Safety Studio and get familiar with the service.
## Content Safety Studio
[Azure AI Content Safety Studio](https://contentsafety.cognitive.azure.com/) is an online tool designed to handle potentially offensive, risky, or undesirable content using cutting-edge content moderation ML models. It provides templates and customized workflows, enabling users to choose and build their own content moderation system. Users can upload their own content or try it out with provided sample content.

## Adding the AI Content Safety service to AI Studio 
Go to your Azure AI Studio Project. \
Choose Project Settings and add a "**New Connection**" for the freshly created Azure AI Content Safety service.

![Alt text](../../media/1234.png)

From the pop up menu, choose "**Azure AI Content Safety**" service.
![Alt text](../../media/1235.png)

Choose the correct service instance and "API Key" as the authentication method. 
![Alt text](../../media/1236.png)

You no longer need to provide service endpoint URL and the service API key. \
Azure AI Search will automatically add the service as an available "tool" that can be added to existing flows.

## Using AI Content Safety within a flow 
Now, let's go back to promptflow and choose the RAG flow created earlier with an "Azure Index" creation. 

