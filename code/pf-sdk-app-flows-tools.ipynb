{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creative Writing Assistant with multiple nodes / tools \n",
    "\n",
    "In this part of the workshop we will build a more sophisticated app leveraging different flow types and tools on promptflow..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Flow \n",
    "You can create LLM apps using a Python function or class as the entry point, which encapsulating your app logic. You can directly test or run these entries with pure code experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"promptflow\": \"1.11.0\",\n",
      "  \"promptflow-core\": \"1.11.0\",\n",
      "  \"promptflow-devkit\": \"1.11.0\",\n",
      "  \"promptflow-tracing\": \"1.11.0\"\n",
      "}\n",
      "\n",
      "Executable '/opt/homebrew/opt/python@3.11/bin/python3.11'\n",
      "Python (Darwin) 3.11.9 (main, Apr  2 2024, 08:25:04) [Clang 15.0.0 (clang-1500.3.9.4)]\n"
     ]
    }
   ],
   "source": [
    "# Confirm Promptflow is installed\n",
    "\n",
    "!pf -v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating flow from scratch...\n",
      "Creating hello.py...\n",
      "Creating data.jsonl...\n",
      "Creating .promptflow folder...\n",
      "Creating __pycache__ folder...\n",
      "Creating flow.dag.yaml...\n",
      "Creating hello.jinja2...\n",
      "Creating /Users/ozgurguler/Developer/Projects/aistudio-workshop-ozguler/code/flow01/requirements.txt...\n",
      "Creating /Users/ozgurguler/Developer/Projects/aistudio-workshop-ozguler/code/flow01/.gitignore...\n",
      "Done. Created standard flow folder: /Users/ozgurguler/Developer/Projects/aistudio-workshop-ozguler/code/flow01.\n",
      "You can execute this command to test the flow, pf flow test --flow flow01 --input flow01/data.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Create a new flow...\n",
    "\n",
    "!pf flow init --flow flow01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run \"flow init\", it creates a folder with name matching flows name (in this case flow01 folder) with necessary files in it.\n",
    "\n",
    "![Alt text](../media/80.png)\n",
    "\n",
    "Structure of the flow folder:\n",
    "\n",
    "- flow.dag.yaml: The flow definition with inputs/outputs, nodes, tools and variants for authoring purpose. \\\n",
    "It defines the structure and logic of the flow, specifying how different tools are connected and how data is passed between them. \\\n",
    "While defining the flow implicitly in app.py is possible, using a flow.yaml file provides several benefits, including better separation of concerns,\\\n",
    "improved readability and maintainability, enhanced reusability and modularity, and a more declarative approach to defining workflows.\\\n",
    "This separation allows for a cleaner, more organized,\n",
    "\n",
    "- .promptflow/flow.tools.json:  contains the tools meta referenced in flow.dag.yaml. We will only run prompty files in this section, which only leverage AzureOpenAI connections defined in .env.\n",
    "Later we will add sections as to how promptflow can leverage LLM connections within AzureAI Studio Hub. However not included in this section.\n",
    "\n",
    "- Source code files (.py, .jinja2): User managed, the code scripts referenced by **tools**.\n",
    "\n",
    "- requirements.txt: Python package dependencies for this flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(If the PromptFlow extension is installed, you can do CMD + K, V to visualise the flow as in the PromptFlow web UI like below.)*\n",
    "\n",
    "![Alt text](../media/81.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the flow skeleton in place, previously created with the *'flow init'* command. \\\n",
    "We will modify the flow so that it has a Python tool step which runs the Prompty file reflecting the recent updates to prompt management in Build,24. \\\n",
    "Let's now update the flow.dag.yaml so that it simply leverages a **python tool** that loads and runs the prompty.prompty. \n",
    "\n",
    "Below is the prompty file for to generate creative writing pieces. \n",
    "(make sure your AOAI endpoint crendtials and base url are added to the .env file in the folder where prompty file is stored.)\n",
    "\n",
    "*creative_writing_assistant.prompty is saved under code/flow01 which you can copy from.*\n",
    "\n",
    "```\n",
    "---\n",
    "name: Creative Writing Assistant\n",
    "description: Generate creative writing prompts and outlines based on a theme.\n",
    "model:\n",
    "  api: chat\n",
    "  configuration:\n",
    "    type: azure_openai\n",
    "    azure_deployment: gpt-35-turbo-16k-ozguler04\n",
    "  parameters:\n",
    "    temperature: 0.7\n",
    "    max_tokens: 2000\n",
    "inputs:\n",
    "  theme:\n",
    "    type: string\n",
    "sample:\n",
    "  theme: \"Mystery and Adventure\"\n",
    "---\n",
    "\n",
    "system:\n",
    "You are an imaginative and supportive creative writing assistant. \n",
    "Your task is to help users generate intriguing writing prompts and provide a brief story outline based on the given theme.\n",
    "\n",
    "user:\n",
    "Theme: {{theme}}\n",
    "\n",
    "assistant:\n",
    "Here is an interesting writing prompt based on the theme \"{{theme}}\":\n",
    "[Generate a complete story here, including an introduction, conflict, rising action, climax, falling action, and resolution, without explicitly labeling these sections.]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the flow.dag.yaml \n",
    "Although we ran the prompty file as a chat app in \"first-pf-sdk-notebook.ipynb\", we will build a more complex app step by step in this notebook. \\\n",
    "Our app will receive a \"theme\" from the user and generate a creative writing piece with users theme. \\\n",
    "\n",
    "Let's start with updating the flow.dag.yaml which to loads and runs the prompty as a promptflow tool. \\\n",
    "*(Refer to the documentation [Using prompty in a flow](https://microsoft.github.io/promptflow/how-to-guides/develop-a-prompty/use-prompty-in-flow.html?highlight=prompty) for more details.)*\n",
    "\n",
    "flow.dag.yaml will accept the \"theme\" as input and will have a single \"node\", a python tool, that will load and run our prompty file. \\\n",
    "copy & paste the below .yaml into flow.dag.yaml.\n",
    "\n",
    "```\n",
    "$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json\n",
    "environment:\n",
    "  python_requirements_txt: requirements.txt\n",
    "inputs:\n",
    "  theme:\n",
    "    type: string\n",
    "outputs:\n",
    "  output_story:\n",
    "    type: string\n",
    "    reference: ${create_story.output}\n",
    "nodes:\n",
    "- name: create_story\n",
    "  type: python\n",
    "  source:\n",
    "    type: code\n",
    "    path: create_story.py\n",
    "  inputs:\n",
    "    theme: ${inputs.theme}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the Python 'tool' that will load and execute the Prompty file \n",
    "\n",
    "```\n",
    "from promptflow.core import Prompty, tool\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables if not already set\n",
    "if \"OPENAI_API_KEY\" not in os.environ and \"AZURE_OPENAI_API_KEY\" not in os.environ:\n",
    "    load_dotenv()\n",
    "\n",
    "@tool\n",
    "def create_story(theme: str) -> str:\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    prompty_file_path = os.path.join(current_dir, \"creative_writing_assistant.prompty\")\n",
    "    print(prompty_file_path)\n",
    "\n",
    "    # Load prompty as a flow\n",
    "    prompty_flow = Prompty.load(prompty_file_path)\n",
    "    result = prompty_flow(theme=theme)\n",
    "    \n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import json\n",
    "    import sys\n",
    "\n",
    "    json_input = sys.argv[1]  # Assume the input is passed as a JSON string\n",
    "    args = json.loads(json_input)\n",
    "\n",
    "    result = create_story(**args)\n",
    "    print(result)\n",
    "```\n",
    "This Python script utilizes the promptflow library to create a story based on a given theme. \\\n",
    "The create_story function is defined as a tool, which reads a .prompty file containing the flow for creative writing,\\\n",
    "executes this flow with the provided theme, and returns the generated story. \\\n",
    "\n",
    "Save the file as **create_story.py** so that it matches the .py file name previously defined in the flow.dag.yaml. \\\n",
    "Next let's run the flow..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-31 09:45:14 +0300][promptflow][INFO] - pf.config.trace.destination: None\n",
      "[2024-05-31 09:45:14 +0300][promptflow][INFO] - resolved tracing.trace.destination: None\n",
      "Prompt flow service has started...\n",
      "[2024-05-31 09:45:14 +0300][promptflow][INFO] - tracer provider is already set, will merge the resource attributes...\n",
      "[2024-05-31 09:45:14 +0300][promptflow][INFO] - tracer provider is updated with resource attributes: BoundedAttributes({'service.name': 'promptflow', 'collection': 'flow01'}, maxlen=None)\n",
      "[2024-05-31 09:45:14 +0300][promptflow][INFO] - have not set exporter to prompt flow service, will set it...\n",
      "[2024-05-31 09:45:14 +0300][promptflow][INFO] - tracer provider is already set, will merge the resource attributes...\n",
      "[2024-05-31 09:45:14 +0300][promptflow][INFO] - tracer provider is updated with resource attributes: BoundedAttributes({'service.name': 'promptflow', 'collection': 'flow01'}, maxlen=None)\n",
      "[2024-05-31 09:45:14 +0300][promptflow][INFO] - exporter to prompt flow service is already set, no action needed.\n",
      "[2024-05-31 09:45:15 +0300][promptflow][INFO] - flow input(s): {'theme': 'Mystery and Adventure'}\n",
      "[2024-05-31 09:45:15 +0300][promptflow][INFO] - tracer provider is already set, will merge the resource attributes...\n",
      "[2024-05-31 09:45:15 +0300][promptflow][INFO] - tracer provider is updated with resource attributes: BoundedAttributes({'service.name': 'promptflow', 'collection': 'flow01'}, maxlen=None)\n",
      "[2024-05-31 09:45:15 +0300][promptflow][INFO] - exporter to prompt flow service is already set, no action needed.\n",
      "2024-05-31 09:45:15 +0300   92486 execution.flow     INFO     Start executing nodes in thread pool mode.\n",
      "2024-05-31 09:45:15 +0300   92486 execution.flow     INFO     Start to run 1 nodes with concurrency level 16.\n",
      "2024-05-31 09:45:15 +0300   92486 execution.flow     INFO     Executing node run_prompty. node run id: e6932349-1a5c-4af0-9915-d61101d17b4c_run_prompty_0\n",
      "2024-05-31 09:45:15 +0300   92486 execution.flow     INFO     [run_prompty in line 0 (index starts from 0)] stdout> /Users/ozgurguler/Developer/Projects/aistudio-workshop-ozguler/code/flow01/creative_writing_assistant.prompty\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow01&uiTraceId=0x11a643599f89c5343b8edfb1bcb9e441\n",
      "2024-05-31 09:45:21 +0300   92486 execution.flow     INFO     Node run_prompty completes.\n",
      "{\n",
      "    \"output_story\": \"Title: The Enigmatic Labyrinth\\n\\nIntroduction:\\nIn the small town of Willow Creek, rumors circulate about a hidden labyrinth deep within the nearby forest. Legend has it that the labyrinth holds a mystical artifact with the power to grant any wish. Four adventurous friends, Jake, Maya, Emma, and Ryan, decide to embark on a journey to uncover the truth behind the mysterious labyrinth.\\n\\nConflict:\\nAs the friends venture into the forest, they encounter a series of puzzling clues and obstacles that test their wits and courage. They soon realize that they are not the only ones searching for the artifact. A notorious treasure hunter named Victor and his team are also after the mythical object, and they will stop at nothing to obtain it.\\n\\nRising Action:\\nJake, Maya, Emma, and Ryan decipher the cryptic hints and navigate the labyrinth's treacherous paths, all while being pursued by Victor and his crew. Along the way, they uncover the labyrinth's secrets and encounter magical creatures that guard the artifact.\\n\\nClimax:\\nIn the heart of the labyrinth, the friends finally reach the chamber where the artifact is said to be. However, they are faced with a moral dilemma: the artifact's power can only be unlocked by sacrificing something dear to them. They must decide whether their wishes are worth the sacrifice.\\n\\nFalling Action:\\nAs the group deliberates, Victor and his crew catch up to them. A tense standoff ensues, with both parties vying for control of the artifact. But just as it seems all hope is lost, the friends come up with a clever plan to outsmart Victor and protect the artifact.\\n\\nResolution:\\nIn a final epic showdown, the friends manage to outwit Victor and secure the artifact. However, instead of using it for their own desires, they decide to keep it hidden within the labyrinth. They realize that the true power lies not in possessing the artifact, but in the journey they undertook together. They return to Willow Creek as heroes, their hearts full of newfound wisdom and friendship. The secret of the labyrinth remains, waiting for another group of adventurers to uncover its mysteries.\"\n",
      "}\n",
      "[2024-05-31 09:45:21 +0300][promptflow][INFO] - Command ran in 7.363 seconds (init: 0.335, invoke: 7.028)\n"
     ]
    }
   ],
   "source": [
    "# Run the flow locally from a Jupyter notebook\n",
    "!pf flow test --flow flow01 --inputs theme=\"Mystery and Adventure\" --verbose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Story Review Step \n",
    "\n",
    "### Create a new prompty for story evaluation\n",
    "First add a new prompty that will be used to prompt for the story evaluation.\n",
    "\n",
    "```\n",
    "---\n",
    "name: Story Evaluation\n",
    "description: Evaluate a story based on key dimensions and suggest improvements.\n",
    "model:\n",
    "  api: chat\n",
    "  configuration:\n",
    "    type: azure_openai\n",
    "    azure_deployment: gpt-35-turbo-16k-ozguler04\n",
    "  parameters:\n",
    "    temperature: 0.7\n",
    "    max_tokens: 1500\n",
    "inputs:\n",
    "  story:\n",
    "    type: string\n",
    "sample:\n",
    "  story: \"Once upon a time in a land far away...\"\n",
    "---\n",
    "\n",
    "system:\n",
    "You are an expert story evaluator. Your task is to evaluate the story based on the following dimensions: creativity, coherence, character depth, engagement, and conflict and resolution. Provide scores out of 10 for each dimension and offer detailed suggestions for improvement.\n",
    "\n",
    "user:\n",
    "Story: {{story}}\n",
    "\n",
    "assistant:\n",
    "Creativity: [Provide a score out of 10 and comments]\n",
    "Coherence: [Provide a score out of 10 and comments]\n",
    "Character Depth: [Provide a score out of 10 and comments]\n",
    "Engagement: [Provide a score out of 10 and comments]\n",
    "Conflict and Resolution: [Provide a score out of 10 and comments]\n",
    "\n",
    "Suggestions for Improvement: [Provide detailed suggestions]\n",
    "```\n",
    "\n",
    "### Updating flow.dag.yaml to add a new python tool node for story evaluation\n",
    "Next, we will add a new step in our flow, which will review the story and suggest improvements.\n",
    "\n",
    "Let's first update the flow.dag.yaml which defines our flow itself. \\\n",
    "We will add a new node (a python tool) named evaluate_story_tool, which will load and run a new prompty that will call an LLM to review the generated story. \\\n",
    "\n",
    "\n",
    "```\n",
    "$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json\n",
    "environment:\n",
    "  python_requirements_txt: requirements.txt\n",
    "inputs:\n",
    "  theme:\n",
    "    type: string\n",
    "outputs:\n",
    "  generated_story:\n",
    "    type: string\n",
    "    reference: ${create_story.output}\n",
    "  evaluation_result:\n",
    "    type: string\n",
    "    reference: ${evaluate_story.output}\n",
    "nodes:\n",
    "- name: create_story\n",
    "  type: python\n",
    "  source:\n",
    "    type: code\n",
    "    path: create_story.py\n",
    "  inputs:\n",
    "    theme: ${inputs.theme}\n",
    "- name: evaluate_story\n",
    "  type: python\n",
    "  source:\n",
    "    type: code\n",
    "    path: evaluate_story.py\n",
    "  inputs:\n",
    "    story: ${create_story.output}\n",
    "```\n",
    "\n",
    "Please note we will output both the created story and the evaluation results. \\\n",
    "Hence above outputs: section include both generations coming from their respective prompts.\n",
    "\n",
    "### Add the new python tool \n",
    "Next create a seperate evaluate_story.py which will be referenced as a python tool that loads and runs the story_evaluation.prompty\n",
    "\n",
    "```\n",
    "from promptflow.core import Prompty, tool\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables if not already set\n",
    "if \"OPENAI_API_KEY\" not in os.environ and \"AZURE_OPENAI_API_KEY\" not in os.environ:\n",
    "    load_dotenv()\n",
    "\n",
    "@tool\n",
    "def evaluate_story(story: str) -> str:\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    evaluation_prompty_file_path = os.path.join(current_dir, \"story_evaluation.prompty\")\n",
    "    print(evaluation_prompty_file_path)\n",
    "\n",
    "    # Load prompty as a flow\n",
    "    evaluation_prompty_flow = Prompty.load(evaluation_prompty_file_path)\n",
    "    evaluation_result = evaluation_prompty_flow(story=story)\n",
    "    \n",
    "    return evaluation_result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import json\n",
    "    import sys\n",
    "\n",
    "    json_input = sys.argv[1]  # Assume the input is passed as a JSON string\n",
    "    args = json.loads(json_input)\n",
    "\n",
    "    result = evaluate_story(**args)\n",
    "    print(result)\n",
    "\n",
    "```\n",
    "\n",
    "Finally let's run our flow again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-31 10:20:10 +0300][promptflow][INFO] - pf.config.trace.destination: None\n",
      "[2024-05-31 10:20:10 +0300][promptflow][INFO] - resolved tracing.trace.destination: None\n",
      "Prompt flow service has started...\n",
      "[2024-05-31 10:20:10 +0300][promptflow][INFO] - tracer provider is already set, will merge the resource attributes...\n",
      "[2024-05-31 10:20:10 +0300][promptflow][INFO] - tracer provider is updated with resource attributes: BoundedAttributes({'service.name': 'promptflow', 'collection': 'flow01'}, maxlen=None)\n",
      "[2024-05-31 10:20:10 +0300][promptflow][INFO] - have not set exporter to prompt flow service, will set it...\n",
      "[2024-05-31 10:20:10 +0300][promptflow][INFO] - tracer provider is already set, will merge the resource attributes...\n",
      "[2024-05-31 10:20:10 +0300][promptflow][INFO] - tracer provider is updated with resource attributes: BoundedAttributes({'service.name': 'promptflow', 'collection': 'flow01'}, maxlen=None)\n",
      "[2024-05-31 10:20:10 +0300][promptflow][INFO] - exporter to prompt flow service is already set, no action needed.\n",
      "[2024-05-31 10:20:10 +0300][promptflow][INFO] - flow input(s): {'theme': 'Mystery and Adventure'}\n",
      "[2024-05-31 10:20:10 +0300][promptflow][INFO] - tracer provider is already set, will merge the resource attributes...\n",
      "[2024-05-31 10:20:10 +0300][promptflow][INFO] - tracer provider is updated with resource attributes: BoundedAttributes({'service.name': 'promptflow', 'collection': 'flow01'}, maxlen=None)\n",
      "[2024-05-31 10:20:10 +0300][promptflow][INFO] - exporter to prompt flow service is already set, no action needed.\n",
      "2024-05-31 10:20:10 +0300   97814 execution.flow     INFO     Start executing nodes in thread pool mode.\n",
      "2024-05-31 10:20:10 +0300   97814 execution.flow     INFO     Start to run 2 nodes with concurrency level 16.\n",
      "2024-05-31 10:20:10 +0300   97814 execution.flow     INFO     Executing node create_story. node run id: 8239b4e1-504a-4ec8-8b2d-6b769765ce9f_create_story_0\n",
      "2024-05-31 10:20:10 +0300   97814 execution.flow     INFO     [create_story in line 0 (index starts from 0)] stdout> /Users/ozgurguler/Developer/Projects/aistudio-workshop-ozguler/code/flow01/creative_writing_assistant.prompty\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow01&uiTraceId=0xf5ef6c15364d8a0f4c2ed2e099804ecd\n",
      "2024-05-31 10:20:15 +0300   97814 execution.flow     INFO     Node create_story completes.\n",
      "2024-05-31 10:20:15 +0300   97814 execution.flow     INFO     Executing node evaluate_story. node run id: 8239b4e1-504a-4ec8-8b2d-6b769765ce9f_evaluate_story_0\n",
      "2024-05-31 10:20:15 +0300   97814 execution.flow     INFO     [evaluate_story in line 0 (index starts from 0)] stdout> /Users/ozgurguler/Developer/Projects/aistudio-workshop-ozguler/code/flow01/story_evaluation.prompty\n",
      "2024-05-31 10:20:22 +0300   97814 execution.flow     INFO     Node evaluate_story completes.\n",
      "{\n",
      "    \"generated_story\": \"Title: The Enigma of the Forgotten Map\\n\\nIntroduction:\\nIn the small town of Willowbrook, a peculiar artifact is discovered within the dusty attic of a long-abandoned mansion. It is an old, weathered map with cryptic symbols and faded markings. Local legend speaks of hidden treasures and unsolved mysteries surrounding the mansion. As news spreads, a group of adventurous friends, Emma, Liam, and Alex, decide to embark on a thrilling journey to uncover the secrets that lie within the forgotten map.\\n\\nConflict:\\nAs the trio delves deeper into deciphering the map's clues, they encounter a series of perplexing challenges. They soon realize that they are not the only ones after the treasure. A secret organization, known as the Shadows, is also aware of the map's existence and will stop at nothing to claim the riches for themselves. Emma, Liam, and Alex find themselves entangled in a dangerous race against time, desperate to unravel the mystery before the Shadows do.\\n\\nRising Action:\\nGuided by the map, the friends traverse treacherous terrains, from dense jungles to ancient ruins. Along the way, they encounter enigmatic puzzles and riddles, each unlocking a new piece of the puzzle. Their bond is tested as they face numerous obstacles, including booby traps, rival treasure hunters, and their own doubts.\\n\\nClimax:\\nThe final clue leads them to an isolated island, where they uncover a hidden cave. Inside, they discover a chamber filled with ancient artifacts, including a legendary gem said to possess unimaginable power. Just as they are about to claim their prize, the Shadows ambush them. A thrilling battle ensues, testing the friends' courage and resourcefulness.\\n\\nFalling Action:\\nDuring the confrontation, Emma realizes that the true power lies not in the gem, but in the knowledge it holds. She makes a daring sacrifice, allowing her friends to escape with the map and the gem, while she stays behind to confront the Shadows. With the gem in their possession, Liam and Alex must find a way to decipher its secrets and fulfill their fallen friend's sacrifice.\\n\\nResolution:\\nThrough Emma's sacrifice, Liam and Alex finally decipher the map's final clue. They uncover the truth behind the treasure, a revelation that has the potential to change the course of history. With the Shadows defeated and the treasure's secret revealed, Emma's memory lives on as a symbol of bravery and friendship. The friends return to Willowbrook, forever changed by their mysterious adventure and the lasting bond they forged along the way.\",\n",
      "    \"evaluation_result\": \"Creativity: 8\\nThe story introduces an intriguing artifact, a forgotten map, and combines it with local legends and a secret organization. The idea of a treasure hunt and the potential for hidden mysteries is engaging and captures the reader's curiosity.\\n\\nCoherence: 9\\nThe story flows well and each section builds upon the previous one, leading to a logical progression of events. The introduction sets the stage for the conflict, and the rising action builds up the suspense. The climax and falling action provide a satisfying resolution to the story.\\n\\nCharacter Depth: 7\\nWhile the characters are introduced and their motivations are briefly mentioned, there is room for further development. The story could benefit from delving deeper into their individual personalities, relationships, and backstories. This would help readers connect more deeply with the characters and become more invested in their journey.\\n\\nEngagement: 9\\nThe story is engaging and keeps the reader hooked with its sense of adventure, mystery, and danger. The pacing is well-maintained, with the introduction effectively setting up the conflict and the rising action providing a series of challenges and obstacles for the characters to overcome. The climax and resolution provide a satisfying conclusion.\\n\\nConflict and Resolution: 8\\nThe conflict is well-established, with the introduction of the secret organization and their pursuit of the treasure. The rising action introduces various obstacles and challenges, increasing the tension and stakes. The climax provides a thrilling battle and the resolution ties up loose ends and delivers a satisfying conclusion. However, it would be beneficial to provide more details about the specific challenges faced by the characters and how they overcome them.\\n\\nSuggestions for Improvement:\\n1. Develop the characters further by providing more details about their personalities, relationships, and backstories. This will help readers connect with them on a deeper level and become more invested in their journey.\\n2. Provide more specific and detailed challenges for the characters to overcome during their treasure hunt. This will increase the sense of danger and excitement, as well as showcase the characters' resourcefulness and problem-solving abilities.\\n3. Consider expanding on the role and motivations of the secret organization, the Shadows. Exploring their backstory and their connection to the mansion and the treasure will add depth to the conflict.\\n4. Add more descriptions of the settings and the artifacts encountered during the adventure. This will help create a vivid and immersive world for the readers to explore alongside the characters.\\n5. Consider adding internal conflicts and personal growth for the characters. This could include moments of doubt, self-reflection, and difficult decisions that test their loyalty and friendship.\\n6. Provide more insight into the consequences of the treasure's revelation and how it could change the course of history. This will add weight to the characters' journey and the importance of their mission.\\n\\nOverall, the story has a strong foundation but could benefit from further development and refinement to enhance the creativity, coherence, character depth, engagement, and conflict resolution.\"\n",
      "}\n",
      "[2024-05-31 10:20:22 +0300][promptflow][INFO] - Command ran in 11.756 seconds (init: 0.067, invoke: 11.689)\n"
     ]
    }
   ],
   "source": [
    "# Run the flow locally from a Jupyter notebook\n",
    "!pf flow test --flow flow01 --inputs theme=\"Mystery and Adventure\" --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-31 12:41:20 +0300][promptflow][INFO] - pf.config.trace.destination: None\n",
      "[2024-05-31 12:41:20 +0300][promptflow][INFO] - resolved tracing.trace.destination: None\n",
      "Prompt flow service has started...\n",
      "[2024-05-31 12:41:20 +0300][promptflow][INFO] - tracer provider is already set, will merge the resource attributes...\n",
      "[2024-05-31 12:41:20 +0300][promptflow][INFO] - tracer provider is updated with resource attributes: BoundedAttributes({'service.name': 'promptflow', 'collection': 'flow01'}, maxlen=None)\n",
      "[2024-05-31 12:41:20 +0300][promptflow][INFO] - have not set exporter to prompt flow service, will set it...\n",
      "[2024-05-31 12:41:20 +0300][promptflow][INFO] - tracer provider is already set, will merge the resource attributes...\n",
      "[2024-05-31 12:41:20 +0300][promptflow][INFO] - tracer provider is updated with resource attributes: BoundedAttributes({'service.name': 'promptflow', 'collection': 'flow01'}, maxlen=None)\n",
      "[2024-05-31 12:41:20 +0300][promptflow][INFO] - exporter to prompt flow service is already set, no action needed.\n",
      "[2024-05-31 12:41:20 +0300][promptflow][INFO] - flow input(s): {'theme': 'Mystery and Adventure'}\n",
      "[2024-05-31 12:41:20 +0300][promptflow][INFO] - tracer provider is already set, will merge the resource attributes...\n",
      "[2024-05-31 12:41:20 +0300][promptflow][INFO] - tracer provider is updated with resource attributes: BoundedAttributes({'service.name': 'promptflow', 'collection': 'flow01'}, maxlen=None)\n",
      "[2024-05-31 12:41:20 +0300][promptflow][INFO] - exporter to prompt flow service is already set, no action needed.\n",
      "2024-05-31 12:41:20 +0300   19300 execution.flow     INFO     Start executing nodes in thread pool mode.\n",
      "2024-05-31 12:41:20 +0300   19300 execution.flow     INFO     Start to run 3 nodes with concurrency level 16.\n",
      "2024-05-31 12:41:20 +0300   19300 execution.flow     INFO     Executing node create_story. node run id: e3f71952-66f6-4777-b799-e0fc3cdaee15_create_story_0\n",
      "2024-05-31 12:41:20 +0300   19300 execution.flow     INFO     [create_story in line 0 (index starts from 0)] stdout> /Users/ozgurguler/Developer/Projects/aistudio-workshop-ozguler/code/flow01/creative_writing_assistant.prompty\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow01&uiTraceId=0x1eea4cf81e7af07de0100f6ea56b486e\n",
      "[2024-05-31 12:41:50 +0300][promptflow.core._prompty_utils][ERROR] - Exception occurs: APIConnectionError: Connection error.\n",
      "2024-05-31 12:41:50 +0300   19300 execution          ERROR    Node create_story in line 0 failed. Exception: OpenAI API hits APIConnectionError: Connection error. [Error reference: https://platform.openai.com/docs/guides/error-codes/api-errors].\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 10, in map_exceptions\n",
      "    yield\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_backends/sync.py\", line 206, in connect_tcp\n",
      "    sock = socket.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py\", line 827, in create_connection\n",
      "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py\", line 962, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "socket.gaierror: [Errno 8] nodename nor servname provided, or not known\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 233, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 268, in handle_request\n",
      "    raise exc\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 251, in handle_request\n",
      "    response = connection.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 8] nodename nor servname provided, or not known\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py\", line 952, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py\", line 1015, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 232, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 8] nodename nor servname provided, or not known\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/promptflow/core/_prompty_utils.py\", line 1003, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/promptflow/core/_flow.py\", line 451, in __call__\n",
      "    response = send_request_to_llm(api_client, self._model.api, params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/promptflow/core/_prompty_utils.py\", line 197, in send_request_to_llm\n",
      "    result = client.chat.completions.create(**parameters)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/promptflow/tracing/_integrations/_openai_injector.py\", line 88, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/promptflow/tracing/_trace.py\", line 513, in wrapped\n",
      "    output = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py\", line 986, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/promptflow/_core/flow_execution_context.py\", line 90, in invoke_tool\n",
      "    result = self._invoke_tool_inner(node, f, kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/promptflow/_core/flow_execution_context.py\", line 201, in _invoke_tool_inner\n",
      "    raise e\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/promptflow/_core/flow_execution_context.py\", line 182, in _invoke_tool_inner\n",
      "    return f(**kwargs)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/promptflow/tracing/_trace.py\", line 513, in wrapped\n",
      "    output = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ozgurguler/Developer/Projects/aistudio-workshop-ozguler/code/flow01/create_story.py\", line 17, in create_story\n",
      "    result = prompty_flow(theme=theme)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/promptflow/tracing/_trace.py\", line 513, in wrapped\n",
      "    output = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/promptflow/core/_prompty_utils.py\", line 1022, in wrapper\n",
      "    raise WrappedOpenAIError(e)\n",
      "promptflow.core._errors.WrappedOpenAIError: OpenAI API hits APIConnectionError: Connection error. [Error reference: https://platform.openai.com/docs/guides/error-codes/api-errors]\n",
      "2024-05-31 12:41:50 +0300   19300 execution.flow     ERROR    Flow execution has failed. Cancelling all running nodes: create_story.\n",
      "[2024-05-31 12:41:50 +0300][promptflow][INFO] - Command ran in 30.376 seconds (init: 0.088, invoke: 30.287)\n",
      "\u001b[31mpf.flow.test failed with UserErrorException: Exception: OpenAI API hits APIConnectionError: Connection error. [Error reference: https://platform.openai.com/docs/guides/error-codes/api-errors]\u001b[0m\n",
      "\u001b[0m\u001b[0mWARNING:azure.monitor.opentelemetry.exporter.export._base:Retrying due to server request error: <urllib3.connection.HTTPSConnection object at 0x10d653f50>: Failed to resolve 'dc.services.visualstudio.com' ([Errno 8] nodename nor servname provided, or not known).\n"
     ]
    }
   ],
   "source": [
    "## Generate and add a relevant image to the Story with Dalle3\n",
    "\n",
    "!pf flow test --flow flow01 --inputs theme=\"Mystery and Adventure\" --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visit the URL specified in your trace to see the outputs formatted properly...(URL will be in a format similar to *http://127.0.0.1:23333/v1.0/ui/traces/?#collection=flow01&uiTraceId=0x76e38b7371180f3ec1b5e01f0bcbfa75*)\n",
    "\n",
    "![Alt text](../media/83.png)\n",
    "\n",
    "With an image generated similar to the below...\n",
    "\n",
    "![Alt text](../media/generated_image.png)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
